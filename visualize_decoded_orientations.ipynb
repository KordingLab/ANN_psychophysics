{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Decoder\n",
    "from data_utils import features_dataset, orientations_iterator\n",
    "from train_utils import train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get orientation dataloader\n",
    "\n",
    "##### We'll get the orientation maps as we load the ImageNet images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL_SIZE = 30\n",
    "assert KERNEL_SIZE in (5,10,15,20,25,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get X data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LAYER_NUMBER = 24\n",
    "assert LAYER_NUMBER in (24,31)\n",
    "\n",
    "feature_num_dict = {24: 100352, 31 :512*7*7}\n",
    "num_features = feature_num_dict[LAYER_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# features_data_train = features_dataset('fast_data/features/vgg_maxpool{}.h5'.format(LAYER_NUMBER), train = True)\n",
    "features_data_valid = features_dataset('fast_data/features/vgg_maxpool{}.h5'.format(LAYER_NUMBER), train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_ftrs = 512*7*7#100352\n",
    "# model = color_predictor(num_ftrs).cuda()\n",
    "\n",
    "model.load_state_dict(torch.load('/home/abenjamin/DNN_illusions/data/models/aritrained_kernel5_0.pt'))\n",
    "\n",
    "# print('done loading')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valdir = '/data2/imagenet/val'\n",
    "# Load the images for visualizing\n",
    "val_dataset_nonnormalized = datasets.ImageFolder(\n",
    "    valdir,\n",
    "    transforms.Compose([\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubsetSampler(torch.utils.data.Sampler):\n",
    "    r\"\"\"Samples elements randomly from a given list of indices, without replacement.\n",
    "\n",
    "    Arguments:\n",
    "        indices (sequence): a sequence of indices\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, indices):\n",
    "        self.indices = indices\n",
    "\n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in range(len(self.indices)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorspacious import cspace_convert\n",
    "\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_viewable(x, y):\n",
    "    \n",
    "    magnitude = torch.sqrt(x**2+y**2)\n",
    "    magnitude /= torch.max(magnitude)\n",
    "    \n",
    "    angle = torch.atan2(y,x)\n",
    "    \n",
    "    color_circle = np.ones((256,3))*66\n",
    "    color_circle[:,1] = np.ones((256))*44\n",
    "\n",
    "    color_circle[:,2] = np.arange(0,360,360/256)\n",
    "    \n",
    "    color_circle_rgb = cspace_convert(color_circle, \"JCh\",\"sRGB1\")\n",
    "    cm = ListedColormap(color_circle_rgb)\n",
    "\n",
    "    a =plt.imshow(angle, \n",
    "                  cmap= cm,\n",
    "                  vmin = -np.pi,\n",
    "                  vmax = np.pi)\n",
    "\n",
    "    plt.imshow(1-magnitude,vmin=0,vmax=1, alpha=.6)\n",
    "    \n",
    "    cbar = plt.colorbar(a, aspect = 10, fraction = .07)\n",
    "    cbar.ax.set_ylabel('Phase [pi]')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get predicted outputs for some inputs\n",
    "\n",
    "TEST_BATCH_SIZE = 64\n",
    "BATCH_SIZE = 2\n",
    "LOG_INTERVAL = 100\n",
    "EPOCHS = 10\n",
    "\n",
    "\n",
    "features_loader_2 = torch.utils.data.DataLoader(features_data_valid,\n",
    "    batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=4, pin_memory=True, drop_last = True)\n",
    "\n",
    "\n",
    "orientation_loader_10 = orientations_iterator('data/features/orientations/{}/all_images.h5'.format(10), \n",
    "                                                      BATCH_SIZE, train = False)\n",
    "orientation_loader_30 = orientations_iterator('data/features/orientations/{}/all_images.h5'.format(30), \n",
    "                                                      BATCH_SIZE, train = False)\n",
    "\n",
    "\n",
    "image_loader = torch.utils.data.DataLoader(val_dataset_nonnormalized,\n",
    "        batch_size=BATCH_SIZE, shuffle=False,sampler = SubsetSampler(range(48000,50000)),\n",
    "        num_workers=1, pin_memory=True)\n",
    "\n",
    "for batch_idx, ((feats, _), orients10,orients30, (images, _)) in enumerate(zip(features_loader_2,\n",
    "                                                                        orientation_loader_10,orientation_loader_30,\n",
    "                                                                       image_loader)):\n",
    "        data1 = feats.cuda()\n",
    "        target = orients30.cuda()\n",
    "        data1 =  Variable(data1)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         output = model(data1)\n",
    "        \n",
    "\n",
    "        for index in range(BATCH_SIZE):\n",
    "            plt.figure(figsize=(10,10))\n",
    "#             plt.subplot(221)\n",
    "#             x,y = output[index].detach().cpu()\n",
    "#             plot_viewable(x, y)\n",
    "#             plt.title(\"Model output\")\n",
    "#             plt.axis(\"off\")\n",
    "            \n",
    "            plt.subplot(222)\n",
    "            x,y = target[index].detach().cpu()\n",
    "            plot_viewable(x, y)\n",
    "            plt.title(\"Loaded orientations: 30\")\n",
    "            plt.axis(\"off\")\n",
    "                        \n",
    "            plt.subplot(224)\n",
    "            x,y = orients10[index].detach().cpu()\n",
    "            plot_viewable(x, y)\n",
    "            plt.title(\"Loaded orientations: 10\")\n",
    "            plt.axis(\"off\")\n",
    "            \n",
    "            plt.subplot(223)\n",
    "            image = images[index]\n",
    "            image = np.squeeze(np.moveaxis(image.numpy(),0,-1))\n",
    "            plt.imshow(image)\n",
    "            plt.title(\"Da pic\")\n",
    "            plt.axis(\"off\")\n",
    "    \n",
    "        \n",
    "         \n",
    "#             magnitude, angle = to_viewable_image(three_d_output)\n",
    "#             magnitude1, angle1 = to_viewable_image(three_d_orient)\n",
    "#             print(\"Output Image\")\n",
    "#             plot_viewable(magnitude, angle)\n",
    "#             print(\"Original Orientation\")\n",
    "#             plot_viewable(magnitude1, angle1)\n",
    "            \n",
    "        break\n",
    "print(\"done\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# compare with the function above\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py34]",
   "language": "python",
   "name": "conda-env-py34-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
